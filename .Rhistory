source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript3.R")
submit()
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
model = lm(y ~ x)
model
model = lm(y ~ 0 + x)
model
data(mtcars)
library(car)
mtcars
model = lm(mpg ~ wt)
model = lm(mpg ~ wt, mtcars)
model
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
x_mean = mean(x)
x_mean
x_std = sd(x)
x[1]
(x[1] - x_mean) / x_std
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
model = lm(y ~ x)
model
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
> y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y ~ x)
lm(x ~ y)
-1.713 / -0.04462
var(y) / var(x)
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
weighted.mean(x, w)
data <- read.csv("D:\R\Getting and Cleaning Data\getdata-wksst8110.for", header=T)
head(data)
dim(data)
file_name <- "getdata_wksst8110.for"
df <- read.fwf(file=file_name,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
head(df)
sum(df[, 4])
data <- read.csv("D:/R/Getting and Cleaning Data/getdata-wksst8110.for", header=T)
head(data)
dim(data)
file_name <- "getdata_wksst8110.for"
df <- read.fwf(file=file_name,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
head(df)
sum(df[, 4])
df <- read.fwf(file=file_name,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
file_name <- "D:/R/Getting and Cleaning Data/getdata-wksst8110.for"
df <- read.fwf(file=file_name,widths=c(-1,9,-5,4,4,-5,4,4,-5,4,4,-5,4,4), skip=4)
head(df)
sum(df[, 4])
data(mtcars)
This analysis reveals that there is a statistically significant difference between the mean and median MPG for automatic and manual transmission cars. All other factors held constant, we observe an increase of 1.80921 in MPG when moving from automatic transition to manual transition systems.
install.packages("ggplot")
installed.packages(gplot2)
installed.packages(ggplot2)
installed.packages("ggplot2")
library("ggplot2")
install.packages("ggplot2")
library("ggplot2")
library(ggplot2)
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package="lubridate")
help(package = lubridate)
this_day <- today()
this_day
day(this_day)
wday(this_day)
wday(this_day, label = TRUE)
this_moment <- now()
this_moment
second(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("192012--")
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
nyc <- now("America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- update(depart, hours = 17, minutes = 34)
depart
arrive <- nyc + hours(15) + minutes(50)
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008", tz = "Singapore")
last_time
?new_interval
how_long <- new_interval(arrival, last_time)
how_long <- new_interval(arrive, last_time)
how_long <- new_interval(arrive, last_time)
how_long <- new_interval(last_time,arrive)
as.period(how_long)
stopwatch()
library(caret)
install.packages("caret")
library(caret)
install.packages("caret")
library(caret)
install.packages("rpart")
library(rpart)
install.packages("rattle")
library(rattle)
install.packages('e1071', dependencies = TRUE)
install.packages("randomForest")
library(randomForest)
install.packages("caret")
install.packages("caret")
library(caret)
install_github('ramnathv/slidify')
library(devtools)
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
library(devtools)
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraries')
library(slidify)
setwd("D:/R/Developing Data Products/Project/")
author("News Sentiment Analysis")
Neg = read.csv("D:/R/Developing Data Products/Project/Dictionary/Negative.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Negative")
GOOG_FIN <- WebCorpus(GoogleFinanceSource("NYSE:RY"))
library(tm)
library(tm.plugin.webmining)
library(SnowballC)
GOOG_FIN <- WebCorpus(GoogleFinanceSource("NYSE:RY"))
ds1g <- tm_map(GOOG_FIN, content_transformer(tolower))
ds2g <- tm_map(ds1g, removePunctuation)
ds3g <- tm_map(ds2g, stripWhitespace)
News_content <- lapply(ds3g, "[[", "content")
News_content[[3]]
dtm = DocumentTermMatrix(News_content[[3]])
dtm = DocumentTermMatrix(ds3g)
terms = colnames(dtm)
terms
Neg_terms <- terms[terms %in% Neg]
News_content[[1]]
length(grep("royal", News_content[[1]]))
length(grep("bank", News_content[[1]]))
News_content[[1]]
library(plyr)
count(News_content[[1]], "bank")
bank <- c("bank")
count(News_content[[1]], "bank")
count(News_content[[1]], "bank")
ds4g <- tm_map(ds3g, stemDocument)
News_content <- lapply(ds4g, "[[", "content")
News_content[[3]]
ds4g <- tm_map(ds3g, content_transformer(removeWords), wordlist)
ds4g <- tm_map(ds3g, content_transformer(removeWords), stopwords("english"))
News_content <- lapply(ds4g, "[[", "content")
News_content[[3]]
ds1g <- tm_map(GOOG_FIN, content_transformer(tolower))
ds2g <- tm_map(ds1g, removePunctuation)
ds3g <- tm_map(ds2g, stripWhitespace)
ds4g <- tm_map(ds3g, content_transformer(removeWords), stopwords("english"))
News_content <- lapply(ds4g, "[[", "content")
News_content[[3]]
GOOG_FIN <- WebCorpus(GoogleFinanceSource("NYSE:RY"))
ds1g <- tm_map(GOOG_FIN, content_transformer(tolower))
ds2g <- tm_map(ds1g, removePunctuation)
ds3g <- tm_map(ds2g, stripWhitespace)
News_content <- lapply(ds4g, "[[", "content")
News_content[[3]]
News_content <- lapply(ds3g, "[[", "content")
News_content[[3]]
News_content[[1]]
dtm = DocumentTermMatrix(News_content)
dtm = DocumentTermMatrix(News_content[[3]])
dtm = DocumentTermMatrix(ds3g)
terms = colnames(dtm)
ds4g <- tm_map(ds3g, removeNumbers)
News_content <- lapply(ds4g, "[[", "content")
dtm = DocumentTermMatrix(ds4g)
terms = colnames(dtm)
terms
dtm
dtm[[1]]
dtm[[2]]
dtm[1]
dtm[[3]]
dtm[[4]]
dtm[[5]]
inspect(dtm)
News_content
dtm = DocumentTermMatrix(News_content)
ds4g
ds4g[[1]]
terms[[1]]
terms
terms[2]
terms[[2]]
Neg_terms
dtm
dtm[[1]]
df <- data.frame(matrix(unlist(dtm)))
View(df)
df <- data.frame(matrix(unlist(dtm)), nrow = 20, byrow = T)
View(df)
df <- data.frame(matrix(unlist(dtm), nrow = 20, byrow = T))
View(df)
df <- data.frame(matrix(unlist(dtm), ncol = 2125, bycol = T))
df <- data.frame(matrix(unlist(dtm), ncol = 2125))
dtm$dimnames$Terms
x<-as.data.frame(dtm)
dtm = DocumentTermMatrix(ds4g)
dtm = TermDocumentMatrix(ds4g)
terms = colnames(dtm)
terms = rownames(dtm)
dtm = DocumentTermMatrix(ds4g)
inspect(dtm[1:20,1:2125])
docs <- as.vector(unlist(ds4g))
Corpus(VectorSource(docs))
GOOG_FIN <- WebCorpus(GoogleFinanceSource("NYSE:RY"))
ds1g <- tm_map(GOOG_FIN, content_transformer(tolower))
ds2g <- tm_map(ds1g, removePunctuation)
ds3g <- tm_map(ds2g, stripWhitespace)
ds4g <- tm_map(ds3g, removeNumbers)
News_content <- lapply(ds4g, "[[", "content")
dtm = DocumentTermMatrix(ds4g)
terms = colnames(dtm)
terms %in% Neg
Neg = read.csv("D:/R/Developing Data Products/Project/Dictionary/Negative.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Negative")
terms %in% Neg
Pos = read.csv("D:/R/Developing Data Products/Project/Dictionary/Positive.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Positive")
terms %in% Pos
View(Neg)
Neg_terms <- terms[terms %in% Neg[,1]]
Neg_scores <- rowSums(as.matrix(dtm[,Neg_terms]))
Pos_Terms <- terms[terms %in% Pos[,1]]
Pos_Scores <- rowSums(as.matrix(dtm[,Pos_terms]))
Pos_Terms <- terms[terms %in% Pos[,1]]
Pos_Scores <- rowSums(as.matrix(dtm[,Pos_Terms]))
Pos_Terms <- Terms[Terms %in% Pos[,1]]
Pos_Scores <- rowSums(as.matrix(dtm[,Pos_Terms]))
Terms <- colnames(DocumentTermMatrix(ds4g))
Pos_Terms <- Terms[Terms %in% Pos[,1]]
Pos_Scores <- rowSums(as.matrix(dtm[,Pos_Terms]))
Terms <- colnames(DocumentTermMatrix(ds4g))
Neg_Terms <- Terms[Terms %in% Neg[,1]]
Neg_Scores <- rowSums(as.matrix(dtm[,Neg_Terms]))
Terms <- colnames(DocumentTermMatrix(ds4g))
Pos_Terms <- Terms[Terms %in% Pos[,1]]
Pos = read.csv("D:/R/Developing Data Products/Project/Dictionary/Positive.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Positive")
View(Pos)
View(Neg)
Pos = read.csv("D:/R/Developing Data Products/Project/Dictionary/Positive.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Positive")
Pos_Terms <- Terms[Terms %in% Pos[,1]]
Pos_Scores <- rowSums(as.matrix(dtm[,Pos_Terms]))
Pos_Scores
Pos_Neg <- Pos_Scores / Neg_Scores
Pos_Neg
Pos = read.csv("D:/R/Developing Data Products/Project/Dictionary/Positive.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Positive")
Neg = read.csv("D:/R/Developing Data Products/Project/Dictionary/Negative.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Negative")
Sng = read.csv("D:/R/Developing Data Products/Project/Dictionary/Strong.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Strong")
Wek = read.csv("D:/R/Developing Data Products/Project/Dictionary/Weak.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Weak")
Act = read.csv("D:/R/Developing Data Products/Project/Dictionary/Active.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Active")
Pas = read.csv("D:/R/Developing Data Products/Project/Dictionary/Passive.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Passive")
Ost = read.csv("D:/R/Developing Data Products/Project/Dictionary/Overstated.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Overstated")
Ust = read.csv("D:/R/Developing Data Products/Project/Dictionary/Understated.csv", stringsAsFactors = FALSE, header = FALSE, col.names = "Understated")
Terms <- colnames(DocumentTermMatrix(ds4g))
Pos_Terms <- Terms[Terms %in% Pos[,1]]
Pos_Scores <- rowSums(as.matrix(dtm[,Pos_Terms]))
Neg_Terms <- Terms[Terms %in% Neg[,1]]
Neg_Scores <- rowSums(as.matrix(dtm[,Neg_Terms]))
Act_Terms <- Terms[Terms %in% Act[,1]]
Act_Scores <- rowSums(as.matrix(dtm[,Act_Terms]))
Pas_Terms <- Terms[Terms %in% Pas[,1]]
Pas_Scores <- rowSums(as.matrix(dtm[,Pas_Terms]))
Sng_Terms <- Terms[Terms %in% Sng[,1]]
Sng_Scores <- rowSums(as.matrix(dtm[,Sng_Terms]))
Wek_Terms <- Terms[Terms %in% Wek[,1]]
Wek_Scores <- rowSums(as.matrix(dtm[,Wek_Terms]))
Ost_Terms <- Terms[Terms %in% Ost[,1]]
Ost_Scores <- rowSums(as.matrix(dtm[,Ost_Terms]))
Ust_Terms <- Terms[Terms %in% Ust[,1]]
Ust_Scores <- rowSums(as.matrix(dtm[,Ust_Terms]))
Pos_Neg <- Pos_Scores / Neg_Scores
Act_Pas <- Act_Scores / Pas_Scores
Sng_Wek <- Sng_Scores / Wek_Scores
Ost_Ust <- Ost_Scores / Ust_Scores
x <- prcomp(Pos_Neg, Act_Pas, Sng_Wek, Ost_Ust)
x <- c(Pos_Neg, Act_Pas, Sng_Wek, Ost_Ust)
x
x[2]
x[,2]
x(,2)
x[[2]]
y <- prcomp(x)
Pos_Neg <- Pos_Scores - Neg_Scores
Act_Pas <- Act_Scores - Pas_Scores
Sng_Wek <- Sng_Scores - Wek_Scores
Ost_Ust <- Ost_Scores - Ust_Scores
sign(Pos_Neg)
sign(Act_Pas)
sing(Sng_Wek)
sign(Sng_Wek)
Ost_Ust
sign(Ost_Ust)
GOOG_FIN <- WebCorpus(GoogleFinanceSource("NYSE:JGW"))
ds1g <- tm_map(GOOG_FIN, content_transformer(tolower))
ds2g <- tm_map(ds1g, removePunctuation)
ds3g <- tm_map(ds2g, stripWhitespace)
ds4g <- tm_map(ds3g, removeNumbers)
News_content <- lapply(ds4g, "[[", "content")
Terms <- colnames(DocumentTermMatrix(ds4g))
Pos_Terms <- Terms[Terms %in% Pos[,1]]
Pos_Scores <- rowSums(as.matrix(dtm[,Pos_Terms]))
Neg_Terms <- Terms[Terms %in% Neg[,1]]
Neg_Scores <- rowSums(as.matrix(dtm[,Neg_Terms]))
Act_Terms <- Terms[Terms %in% Act[,1]]
Act_Scores <- rowSums(as.matrix(dtm[,Act_Terms]))
Pas_Terms <- Terms[Terms %in% Pas[,1]]
Pas_Scores <- rowSums(as.matrix(dtm[,Pas_Terms]))
Sng_Terms <- Terms[Terms %in% Sng[,1]]
Sng_Scores <- rowSums(as.matrix(dtm[,Sng_Terms]))
Wek_Terms <- Terms[Terms %in% Wek[,1]]
Wek_Scores <- rowSums(as.matrix(dtm[,Wek_Terms]))
Ost_Terms <- Terms[Terms %in% Ost[,1]]
Ost_Scores <- rowSums(as.matrix(dtm[,Ost_Terms]))
Ust_Terms <- Terms[Terms %in% Ust[,1]]
Ust_Scores <- rowSums(as.matrix(dtm[,Ust_Terms]))
Pos_Neg <- Pos_Scores - Neg_Scores
Act_Pas <- Act_Scores - Pas_Scores
Sng_Wek <- Sng_Scores - Wek_Scores
Ost_Ust <- Ost_Scores - Ust_Scores
dtm <- DocumentTermMatrix(ds4g)
Pos_Terms <- Terms[Terms %in% Pos[,1]]
Pos_Scores <- rowSums(as.matrix(dtm[,Pos_Terms]))
Neg_Terms <- Terms[Terms %in% Neg[,1]]
Neg_Scores <- rowSums(as.matrix(dtm[,Neg_Terms]))
Act_Terms <- Terms[Terms %in% Act[,1]]
Act_Scores <- rowSums(as.matrix(dtm[,Act_Terms]))
Pas_Terms <- Terms[Terms %in% Pas[,1]]
Pas_Scores <- rowSums(as.matrix(dtm[,Pas_Terms]))
Sng_Terms <- Terms[Terms %in% Sng[,1]]
Sng_Scores <- rowSums(as.matrix(dtm[,Sng_Terms]))
Wek_Terms <- Terms[Terms %in% Wek[,1]]
Wek_Scores <- rowSums(as.matrix(dtm[,Wek_Terms]))
Ost_Terms <- Terms[Terms %in% Ost[,1]]
Ost_Scores <- rowSums(as.matrix(dtm[,Ost_Terms]))
Ust_Terms <- Terms[Terms %in% Ust[,1]]
Ust_Scores <- rowSums(as.matrix(dtm[,Ust_Terms]))
Pos_Neg <- Pos_Scores - Neg_Scores
Act_Pas <- Act_Scores - Pas_Scores
Sng_Wek <- Sng_Scores - Wek_Scores
Ost_Ust <- Ost_Scores - Ust_Scores
sign(Pos_Neg)
sign(Sng_Wek)
GOOG_FIN <- WebCorpus(GoogleFinanceSource("NYSE:MIL"))
ds1g <- tm_map(GOOG_FIN, content_transformer(tolower))
ds2g <- tm_map(ds1g, removePunctuation)
ds3g <- tm_map(ds2g, stripWhitespace)
ds4g <- tm_map(ds3g, removeNumbers)
News_content <- lapply(ds4g, "[[", "content")
Terms <- colnames(DocumentTermMatrix(ds4g))
dtm <- DocumentTermMatrix(ds4g)
Pos_Terms <- Terms[Terms %in% Pos[,1]]
Pos_Scores <- rowSums(as.matrix(dtm[,Pos_Terms]))
Neg_Terms <- Terms[Terms %in% Neg[,1]]
Neg_Scores <- rowSums(as.matrix(dtm[,Neg_Terms]))
Act_Terms <- Terms[Terms %in% Act[,1]]
Act_Scores <- rowSums(as.matrix(dtm[,Act_Terms]))
Pas_Terms <- Terms[Terms %in% Pas[,1]]
Pas_Scores <- rowSums(as.matrix(dtm[,Pas_Terms]))
Sng_Terms <- Terms[Terms %in% Sng[,1]]
Sng_Scores <- rowSums(as.matrix(dtm[,Sng_Terms]))
Wek_Terms <- Terms[Terms %in% Wek[,1]]
Wek_Scores <- rowSums(as.matrix(dtm[,Wek_Terms]))
Ost_Terms <- Terms[Terms %in% Ost[,1]]
Ost_Scores <- rowSums(as.matrix(dtm[,Ost_Terms]))
Ust_Terms <- Terms[Terms %in% Ust[,1]]
Ust_Scores <- rowSums(as.matrix(dtm[,Ust_Terms]))
Pos_Neg <- Pos_Scores - Neg_Scores
Act_Pas <- Act_Scores - Pas_Scores
Sng_Wek <- Sng_Scores - Wek_Scores
Ost_Ust <- Ost_Scores - Ust_Scores
sign(Pos_Neg)
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
Pos_Neg_Sentiment < sum(sign(Pos_Neg) == 1) / sum(sign(Pos_Neg) !=0)
Pos_Neg_Sentiment <- sum(sign(Pos_Neg) == 1) / sum(sign(Pos_Neg) !=0)
Pos_Neg_Sentiment
Pos_Neg <- Mean(Pos_Scores - Neg_Scores)
Pos_Neg <- Average(Pos_Scores - Neg_Scores)
Pos_Neg <- (Pos_Scores - Neg_Scores)
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
GOOG_FIN <- WebCorpus(GoogleFinanceSource("NYSE:MIL"))
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
shiny::runApp('D:/R/Developing Data Products/Project')
publish_rpubs(title, html_file = "index.html")
publish(title = 'mytitle', 'index.html', host = 'rpubs')
install.packages("publish")
library(slidify)
library(slidifyLibraries)
publish(title = 'mytitle', 'index.html', host = 'rpubs')
setwd("D:/R/Developing Data Products/Project/News Sentiment Analysis")
publish(title = 'mytitle', 'index.html', host = 'rpubs')
